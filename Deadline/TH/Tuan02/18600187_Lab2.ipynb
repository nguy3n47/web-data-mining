{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Lab02-WebCrawler.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoZsSp4puEDV"
      },
      "source": [
        "# Lab02: Web Crawler (Continue).\n",
        "\n",
        "- MSSV: 18600187\n",
        "- Họ và tên: Vũ Cao Nguyên"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmqGzCH5uEDf"
      },
      "source": [
        "## Yêu cầu bài tập\n",
        "\n",
        "**Cách làm bài**\n",
        "\n",
        "\n",
        "Bạn sẽ làm trực tiếp trên file notebook này; trong file, từ `TODO` để cho biết những phần mà bạn cần phải làm.\n",
        "\n",
        "Bạn có thể thảo luận ý tưởng cũng như tham khảo các tài liệu, nhưng *code và bài làm phải là của bạn*. \n",
        "\n",
        "Nếu vi phạm thì sẽ bị 0 điểm cho bài tập này.\n",
        "\n",
        "**Cách nộp bài**\n",
        "\n",
        "Trước khi nộp bài, rerun lại notebook (`Kernel` -> `Restart & Run All`).\n",
        "\n",
        "Sau đó, tạo thư mục có tên `MSSV` của bạn (vd, nếu bạn có MSSV là 1234567 thì bạn đặt tên thư mục là `1234567`) Chép file notebook, file `output.txt` và file data các bạn đã lưu vào rồi nén thư mục `MSSV` này lại và nộp trên moodle.\n",
        "\n",
        "**Nội dung bài tập**\n",
        "\n",
        "Thu thập và thể hiện dữ liệu web."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGaBmMiruEDh"
      },
      "source": [
        "## 2. Cài đặt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80GpBEd8uEDh"
      },
      "source": [
        "### 2.1. Import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QohcqAMxuEDi"
      },
      "source": [
        "import requests\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from bs4.element import Comment\n",
        "import string"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aULyGH_quEDi"
      },
      "source": [
        "### 2.2. HTML Parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw9ZvBxSuEDj"
      },
      "source": [
        "\n",
        "Bộ phân tích cú pháp HTML (HTML Parser): nhận HTML code và trích xuất thông tin liên quan như tiêu đề của trang, đoạn văn trong trang, tiêu đề trong trang, liên kết, văn bản in đậm, v.v."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFC1dbwQuEDj",
        "outputId": "be63e141-a15c-41c4-ebaf-3330138a1903",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from html.parser import HTMLParser\n",
        "\n",
        "class MyHTMLParser(HTMLParser):\n",
        "    def handle_starttag(self, tag, attrs):\n",
        "        print(\"Start tag:\", tag)\n",
        "\n",
        "    def handle_endtag(self, tag):\n",
        "        print(\"End tag :\", tag)\n",
        "\n",
        "    def handle_data(self, data):\n",
        "        print(\"Data  :\", data)\n",
        "\n",
        "parser = MyHTMLParser()\n",
        "parser.feed('<html><head><title>Test</title></head>')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start tag: html\n",
            "Start tag: head\n",
            "Start tag: title\n",
            "Data  : Test\n",
            "End tag : title\n",
            "End tag : head\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKAsSsJeuEDl"
      },
      "source": [
        "#### Loại bỏ các HTML tag không cần thiết bằng cách thiết lập filter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1U_khTNuEDl"
      },
      "source": [
        "def text_filter(element):\n",
        "    if element.parent.name in ['style', 'title', 'script', 'head', '[document]', 'class', 'a', 'li']:\n",
        "        return False\n",
        "    elif isinstance(element, Comment):\n",
        "        '''Opinion mining?'''\n",
        "        return False\n",
        "    elif re.match(r\"[\\s\\r\\n]+\",str(element)): \n",
        "        '''space, return, endline'''\n",
        "        return False\n",
        "    return True"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrVkJXcuud-o",
        "outputId": "544038d9-7b45-4f3e-a554-da8209d75af3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcjMt6OsuEDm"
      },
      "source": [
        "### 2.4 Thu thập nội dung trang Web"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY1x9mfGuEDm"
      },
      "source": [
        "#### Trong bài tập này ta thể hiện tài liệu (hay nội dung trang web) với cấu trúc đơn giản như sau: \n",
        "- Gọi $D$ là một tập tài liệu chứa *n* tài liệu: $D=\\left\\{d_1,d_2,...,d_n\\right\\}$.\n",
        "- Ta thể hiện tài liệu bằng một dictionary `data={}` với `data[word]=[[url_idx_1,url_idx_2,...],frequency]` với `url_index`$\\in{\\left[{1,n}\\right]}$\n",
        "\n",
        "VD: `data['at']=[[1,2], 5]`\n",
        "Từ `at` xuất hiện trong đường dẫn có index `1` và `2` tổng số lần xuất hiện là 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la1xrNmCuEDm"
      },
      "source": [
        "#### Bước 1: liệt kê các từ xuất hiện trong trang web:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIDd7SfvuEDn"
      },
      "source": [
        "def wordList(url):\n",
        "    r=requests.get(url)\n",
        "    soup=BeautifulSoup(r.content,\"html.parser\")\n",
        "    text=soup.findAll(text=True)\n",
        "    filtered_text=list(filter(text_filter,text))\n",
        "    word_list=[]\n",
        "\n",
        "    #TODO:\n",
        "    #c in string.punctuation\n",
        "    for ch in filtered_text:\n",
        "      for index in ch:\n",
        "        if index in string.punctuation:\n",
        "          ch = ch.replace(index,' ')\n",
        "      ch = ch.split()\n",
        "      for index in ch:\n",
        "        word_list.append(index)\n",
        "\n",
        "    return word_list"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoCxPw8guEDn"
      },
      "source": [
        "#### Bước 2: Tính tần suất xuất hiện của từ trong 1 trang web, lưu trữ dữ liệu vào data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1R-k7S2uEDn"
      },
      "source": [
        "def read_url(url, url_idx, data):\n",
        "    word_list = wordList(url)\n",
        "\n",
        "    for index in word_list:\n",
        "      index = index.lower()\n",
        "      if data.get(index) is None:\n",
        "        data[index] = [[url_idx],1]\n",
        "      else:\n",
        "        if url_idx in data[index][0]:\n",
        "          data[index][1]+=1\n",
        "        else:\n",
        "          data[index][0].append(url_idx)\n",
        "    \n",
        "    #TODO\n",
        "    '''Initialize value: data[w] = [[url_idx], 1]'''\n",
        "                                    #list_url\n",
        "    #VD: data.get(\"at\")==None => initialize data[\"at\"]\n",
        "        # data.get(\"at\")!=None >= add url_idx to list_url_idx (remember to check if this url_idx is in list_url_idx), \n",
        "                                # frequence+=1\n",
        "    return 1  "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6an8ftouEDo"
      },
      "source": [
        "#### Bước 3: Chạy chương trình lưu kết quả vào file output.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw2F5oRPuEDo"
      },
      "source": [
        "data={}\n",
        "read_url('https://en.wikipedia.org/wiki/Web_mining', 1,data)\n",
        "read_url('https://en.wikipedia.org/wiki/Data_mining', 2,data)\n",
        "\n",
        "sorted_keys = sorted(data.keys())\n",
        "\n",
        "with open(\"output.txt\", \"w\",encoding=\"utf-8\") as f:\n",
        "    output_line = \"Word\".ljust(20) + \"Frequency\".ljust(15) + \"URL_idx\".ljust(15) + \"\\n\"\n",
        "    f.writelines(output_line)\n",
        "    f.writelines('---------------------------------------------------------------------\\n\\n')\n",
        "    for key in sorted_keys:\n",
        "        output_string = str(key).ljust(20) + str(data[key][1]).ljust(15) + str(data[key][0]).ljust(15) + \"\\n\"\n",
        "        f.writelines(output_string)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF3seu1yuEDp"
      },
      "source": [
        "#TODO\n",
        "#Use python pickle save data. Load and print 10 first data values\n",
        "# with open(dumpfile_path, \"rb\") as f:\n",
        "import pickle\n",
        "\n",
        "with open('18600187', \"wb\") as f:\n",
        "  pickle.dump(data, f)\n",
        "with open('18600187', \"rb\") as f:\n",
        "  data = pickle.load(f)"
      ],
      "execution_count": 38,
      "outputs": []
    }
  ]
}